{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Oct  2 23:06:45 2019\n",
    "\n",
    "@author: p5hngk\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Ce code permet de calculer le nombre de \"bonds\" entre deux urls: url_start and url_finish\n",
    "Le test est ici effectué avec des pages wikipédia pour vérifier si tous les articles de la \n",
    "version anglaise de Wikipédia mènent à l'article «Philosophy». Plus précisément, \n",
    "si l'on clique sur le premier lien de chaque article, on tombera, au bout d'un moment,\n",
    "sur l'article Philosophy. \n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link(url):\n",
    "    \"\"\"\n",
    "    Permet d'obtenir le premier lien trouver dans une page Wikipédia.\n",
    "    \"\"\"\n",
    "    link = None\n",
    "\n",
    "    content = requests.get(url)\n",
    "    soup = BeautifulSoup(content.text, features=\"html.parser\")\n",
    "    \n",
    "    #  Séléction d'un paragraphe de texte\n",
    "    paragraph = soup.select(\"p\")\n",
    "    for p in paragraph:\n",
    "        a = p.find(\"a\")\n",
    "        if a:\n",
    "            link = a.get('href')\n",
    "            break\n",
    "            \n",
    "    if link:\n",
    "        # Reconstruction d'une url complète\n",
    "        link = urllib.parse.urljoin('https://en.wikipedia.org/', link)\n",
    "\n",
    "    return link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_urls(url_start, url_finish, max_iter=30):\n",
    "    \"\"\"\n",
    "    Construction de la chaîne d'urls.\n",
    "    \"\"\"\n",
    "    urls = []\n",
    "\n",
    "    flag_remove_first = False\n",
    "    if 'Special:Random' in url_start:\n",
    "        flag_remove_first = True\n",
    "\n",
    "    urls.append(url_start)\n",
    "\n",
    "    while True:\n",
    "        # Obtention du prochain lien à partir du dernier élément de la liste d'urls\n",
    "        link = get_link(urls[-1])\n",
    "        if not link:\n",
    "            urls = None\n",
    "            break\n",
    "\n",
    "        urls.append(link)\n",
    "        \n",
    "        if urls[-1] == url_finish:\n",
    "            if flag_remove_first:\n",
    "                urls.pop(0) \n",
    "            print(\"\\n Il faut {} bonds entre {} et {}\".format(len(urls), urls[0], urls[-1]))\n",
    "            break\n",
    "        elif len(urls) > max_iter:\n",
    "            if flag_remove_first:\n",
    "                urls.pop(0) \n",
    "            print(\"\\n Arrêt ! La recherche entre {} et {} est trop longue (plus de {} bonds)!\".format(urls[0],\n",
    "                                                                                url_finish,\n",
    "                                                                                max_iter))\n",
    "            break\n",
    "        elif link in urls[:-1]:\n",
    "            print(\"\\n Arrêt ! La recherche tourne en boucle : deux passages sur {}\".format(link))\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "                 \n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Il faut 13 bonds entre https://en.wikipedia.org/wiki/Mathematics et https://en.wikipedia.org/wiki/Philosophy\n",
      "\n",
      " Il faut 9 bonds entre https://en.wikipedia.org/wiki/Molecular_biophysics et https://en.wikipedia.org/wiki/Philosophy\n",
      "\n",
      "\n",
      "\n",
      " Tests sur des URLs Wikipédia aléatoires (/wiki/Special:Random)\n",
      "\n",
      " Il faut 19 bonds entre https://en.wikipedia.org/wiki/Mike_Turzai et https://en.wikipedia.org/wiki/Philosophy\n",
      "\n",
      " Il faut 16 bonds entre https://en.wikipedia.org/wiki/Public_transport et https://en.wikipedia.org/wiki/Philosophy\n",
      "\n",
      " Fin du programme ! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__': \n",
    "\n",
    "    url_start = \"https://en.wikipedia.org/wiki/Mathematics\"\n",
    "    url_finish = \"https://en.wikipedia.org/wiki/Philosophy\"\n",
    "    urls = go_urls(url_start, url_finish)\n",
    "\n",
    "    url_start = \"https://en.wikipedia.org/wiki/Molecular_biophysics\"\n",
    "    urls = go_urls(url_start, url_finish)\n",
    "    \n",
    "    \n",
    "    # Tests sur des urls Wikipédia aléatoires\n",
    "    print(\"\\n\")\n",
    "    print(\"\\n Tests sur des URLs Wikipédia aléatoires (/wiki/Special:Random)\")\n",
    "    \n",
    "    \n",
    "    url_start = \"https://en.wikipedia.org/wiki/Special:Random\"\n",
    "   \n",
    "    for i in range(3):\n",
    "        urls = go_urls(url_start, url_finish)\n",
    "        \n",
    "    print(\"\\n Fin du programme ! \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
